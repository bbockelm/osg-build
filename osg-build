#!/usr/bin/env python2
import atexit
from glob import glob
import grp
import fnmatch as fnmatch_
from fnmatch import fnmatch
import logging
from optparse import OptionParser
import os
import re
import shutil
from socket import getfqdn
import subprocess
import sys
import tempfile
import time
import urllib2
from ConfigParser import ConfigParser
import traceback

from osg_build_lib.constants import *
from osg_build_lib.utils import *
from osg_build_lib.koji import *
from osg_build_lib.error import *
from osg_build_lib.mock import link_mock_extra_config_files, make_mock_config, make_mock_config_from_koji, Mock

__version__ = '@VERSION@'


def check_uncommitted(package_dir):
    """Return True if there are uncommitted changes in the SVN working dir."""
    out, err = sbacktick("svn status -q " + package_dir)
    if err:
        print >>sys.stderr, "error getting svn status"
        return None
    if out:
        print "The following uncommitted changes exist:"
        print out
        return True
    else:
        return False


def get_package_svn_url_rev(package_dir):
    out, err = sbacktick("svn info " + package_dir)
    # TODO better err handling
    if err:
        return None
    url = None
    rev = None
    for line in out.split("\n"):
        label, value = line.split(": ", 1)
        if label == "URL":
            url = re.sub("^" + re.escape(SVN_AFS_ROOT), SVN_ROOT, value)
        elif label == "Revision":
            rev = value
    
    return (url, rev)


class OSGBuild(object):
    def __init__(self, package_dir, opts, mock_obj=None, koji_obj=None):
        self.package_dir = package_dir
        self.mock_obj = mock_obj
        self.koji_obj = koji_obj

        self.options = opts.copy()

        if self.options['svn']:
            self.abs_package_dir = None
            self.package_name = os.path.basename(re.sub(r'@\d+$', '', package_dir))
            self.working_subdir = None
            self.results_dir = None
            self.prebuild_dir = None
            self.unpacked_dir = None
            self.unpacked_tarball_dir = None
        else:
            self.abs_package_dir = os.path.abspath(self.package_dir)
            self.package_name = os.path.basename(self.abs_package_dir)
            # Unless working_directory is '.', i.e. we want to put the wd's in
            # the package dir, get rid of any parent or current directory
            # components so doing "osg-build pre -w TEMP ../foobar" won't put stuff
            # in "/tmp/foobar"
            if (os.path.realpath(self.options['working_directory']) !=
                    os.path.realpath('.')):
                package_dir_no_parent = re.sub(r'^(\.\.?/)+', '', package_dir)
                self.working_subdir = os.path.abspath(
                    os.path.join(
                        self.options['working_directory'], package_dir_no_parent))
            else:
                self.working_subdir = os.path.abspath(
                    os.path.join(
                        self.options['working_directory'], package_dir))
            safe_makedirs(self.working_subdir)
            self.results_dir = os.path.join(self.working_subdir, WD_RESULTS)
            self.prebuild_dir = os.path.join(self.working_subdir, WD_PREBUILD)
            self.unpacked_dir = os.path.join(self.working_subdir, WD_UNPACKED)
            self.unpacked_tarball_dir = os.path.join(self.working_subdir, WD_UNPACKED_TARBALL)

            if self.options['autoclean']:
                for dir in [self.results_dir, self.prebuild_dir, self.unpacked_dir, self.unpacked_tarball_dir]:
                    if os.path.exists(dir):
                        logging.debug("autoclean removing " + dir)
                        shutil.rmtree(dir)

    
    def get_rpmbuild_defines(self, prebuild):
        """Get a list of --define arguments to pass to rpmbuild based on the
        working dir and the subdirectories specified in the WD_* constants.

        """
        defines = [
            "_build_name_fmt %%{NAME}-%%{VERSION}-%%{RELEASE}.%%{ARCH}.rpm",
            "_topdir " + self.working_subdir,
            "dist ." + self.options.get('distro_tag', 'osg')]

        if prebuild:
            defines += [
                "_builddir " + self.prebuild_dir,
                "_buildrootdir " + self.prebuild_dir,
                "_rpmdir " + self.prebuild_dir,
                "_sourcedir " + self.prebuild_dir,
                "_specdir " + self.prebuild_dir,
                "_srcrpmdir " + self.prebuild_dir,
                "_tmppath " + self.prebuild_dir]
        else:
            defines += [
                "_builddir " + os.path.join(self.results_dir, "BUILD"),
                "_buildrootdir " + os.path.join(self.results_dir, "BUILDROOT"),
                "_rpmdir " + self.results_dir,
                "_sourcedir " + self.results_dir,
                "_specdir " + self.results_dir,
                "_srcrpmdir " + self.results_dir,
                "_tmppath " + os.path.join(self.results_dir, "tmp")]

        return ['--define=' + d for d in defines]


    def make_srpm(self, spec_fn):
        """Make an SRPM from a spec function. Raise OSGPrebuildError on
        failure.

        """
        cmd = ["rpmbuild", "-bs", "--nodeps"]
        cmd += self.get_rpmbuild_defines(prebuild=True)
        cmd += [spec_fn]
        err_msg_prefix = (("Error making SRPM from %s\n" +
                           "Command used was: %s\n") %
                           (spec_fn, " ".join(cmd)))
        try:
            output = checked_backtick(cmd, nostrip=True, err2out=True)
        except CalledProcessError, e:
            logging.error("Rpmbuild failed. Output follows: " + e.output)
            raise OSGPrebuildError(err_msg_prefix +
                                   "Rpmbuild return code %d" % e.returncode)

        match = re.search(r"(?ms)^Wrote: ([^\n]+.src.rpm)$", output)
        if match:
            srpm = match.group(1).strip()
            if os.path.isfile(srpm):
                return srpm
        raise OSGPrebuildError(err_msg_prefix +
                               "Unable to find resulting SRPM.")


    def process_dot_source(self, sfilename, destdir):
        """Read a .source file, fetch any files mentioned in it from the
        cache.

        """
        safe_makedirs(destdir)
        downloaded = []
        try:
            sfile = open(sfilename, 'r')
            for lineno, line in enumerate(sfile):
                line = line.strip()
                if line.startswith('#'): continue
                if line == '': continue
                basename = os.path.basename(line)
                if line.startswith('/'):
                    uri = "file://" + line
                    logging.warning(
                        "An absolute path has been given in %s line %d. " +
                        "It is recommended to use only paths relative to %s" +
                        "in your source files.", sfilename, lineno+1,
                        self.options['cache_prefix'])
                elif not re.match(r'/|\w+://', line): # relative path
                    uri = os.path.join(self.options['cache_prefix'], line)
                else:
                    uri = line

                logging.info('Retrieving ' + uri)
                handle = urllib2.urlopen(uri)
                filename = os.path.join(destdir, basename)
                desthandle = open(filename, 'w')
                desthandle.write(handle.read())
                downloaded.append(filename)
        finally:
            sfile.close()

        return downloaded


    def prebuild_extsrc(self, destdir=None):
        """Prebuild packages with external sources.
        Process *.source files in upstream/ directory, downloading upstream
        sources mentioned in them from the software cache. Unpack SRPMs if
        there are any. Override upstream files with those in the osg/
        directory.

        """
        if destdir is None:
            destdir = self.prebuild_dir

        upstream_dir = os.path.join(self.abs_package_dir, 'upstream')
        osg_dir = os.path.join(self.abs_package_dir, 'osg')

        # Process upstream/*.source files
        dot_sources = glob(os.path.join(upstream_dir, '*.source'))
        downloaded = []
        for s in dot_sources:
            logging.debug('Processing .source file %s', s)
            downloaded += [
                os.path.abspath(x)
                for x in self.process_dot_source(s, destdir)]

        # Process downloaded SRPMs
        srpms = fnmatch_.filter(downloaded, '*.src.rpm')
        if srpms:
            safe_makedirs(self.unpacked_dir)
            for s in srpms:
                shutil.move(s, self.unpacked_dir)
            moved_srpms = glob(os.path.join(self.unpacked_dir, "*.src.rpm"))
            old_dir = os.getcwd()
            os.chdir(self.unpacked_dir)
            for s in moved_srpms:
                logging.info("Unpacking SRPM " + s)
                super_unpack(s)
                os.unlink(s)
            os.chdir(old_dir)
            for f in glob(os.path.join(self.unpacked_dir, '*')):
                logging.debug('Copying unpacked file ' + f)
                shutil.copy(f, destdir)

        # Process other files in upstream
        other_sources = [x for x in glob(os.path.join(upstream_dir, '*'))
                         if not fnmatch(x, '*.source')]
        for s in other_sources:
            bn = os.path.basename(s)
            if bn in [WD_RESULTS, WD_PREBUILD, WD_UNPACKED,
                      WD_UNPACKED_TARBALL] or bn.endswith('~'):
                logging.debug('Skipping other source ' + s)
                continue
            logging.debug('Copying other source ' + s)
            shutil.copy(s, destdir)

        if self.options.get('full_extract'):
            # Extract any archives we downloaded plus any archives in the SRPM
            if os.path.isdir(self.unpacked_dir):
                downloaded += [
                    os.path.abspath(x)
                    for x in glob(os.path.join(self.unpacked_dir,'*'))
                    if os.path.isfile(x)]
            safe_makedirs(self.unpacked_tarball_dir)
            old_dir = os.getcwd()
            os.chdir(self.unpacked_tarball_dir)
            for f in downloaded:
                logging.info("Extracting " + f)
                super_unpack(f)
            os.chdir(old_dir)
            logging.info('Extracted files to ' + self.unpacked_tarball_dir)

        # Override downloaded files with what's in osg/
        if os.path.isdir(osg_dir):
            for f in glob(os.path.join(osg_dir, '*')):
                bn = os.path.basename(f)
                if bn in [WD_RESULTS, WD_PREBUILD, WD_UNPACKED,
                          WD_UNPACKED_TARBALL] or bn.endswith('~'):
                    logging.debug('Skipping ' + f)
                    continue
                logging.debug('Copying osg file ' + f)
                shutil.copy(f, destdir)

        spec_glob = os.path.join(self.prebuild_dir, '*.spec')
        spec_filenames = glob(spec_glob)
        if not spec_filenames:
            raise GlobNotFoundError(spec_glob)
        
        return spec_filenames
        

    def prebuild(self):
        """Prebuild the package in package_dir: create an SRPM containing
        upstream sources (if any) plus our changes (if any) plus a spec file.
        
        Return the name of the SRPM created.

        """
        safe_makedirs(self.prebuild_dir)
        self.prebuild_extsrc()

        spec_filenames = self.prebuild_extsrc()

        result_srpm = self.make_srpm(spec_filenames[0])

        if result_srpm:
            logging.info("Files have been prepared in %s.", self.prebuild_dir)
            return os.path.abspath(result_srpm)

    
    def quilt(self):
        if not which("quilt"):
            raise ProgramNotFoundError("quilt")

        safe_makedirs(self.prebuild_dir)
        spec_filenames = self.prebuild_extsrc()

        os.chdir(self.prebuild_dir)
        ret = unchecked_call(["quilt", "-v", "setup", spec_filenames[0]])
        if ret != 0:
            raise OSGBuildError("Error running 'quilt setup' on the spec file.")

        logging.info("quilt files ready in %s", self.prebuild_dir)


    def prepare(self):
        """Runs rpmbuild -bp"""
        srpm = self.prebuild()
        safe_makedirs(self.results_dir)
        shutil.copy(srpm, self.results_dir)
        for d in ['BUILD', 'tmp']:
            safe_makedirs(os.path.join(self.results_dir, d))
        cmd = ["rpm"]
        cmd += self.get_rpmbuild_defines(prebuild=False)
        cmd += ["-i", srpm]
        try:
            checked_call(cmd)
        except CalledProcessError:
            raise Error("Unable to unpack SRPM: error while running rpm -i")

        cmd2 = ["rpmbuild"]
        cmd2 += self.get_rpmbuild_defines(prebuild=False)
        cmd2 += ["-bp"] + glob(os.path.join(self.results_dir, "*.spec"))
        cmd2 += ["--nodeps"]
        if self.options.has_key('target_arch'):
            cmd2 += ["--target", self.options['target_arch']]
        try:
            checked_call(cmd2)
        except CalledProcessError:
            raise Error(
                "Unable to prepare the package: error running rpmbuild -bp")
        logging.info("Files prepared in: " +
                     os.path.join(self.results_dir, "BUILD"))


    def rpmbuild(self):
        """Build the package using rpmbuild on the local machine."""
        srpm = self.prebuild()
        safe_makedirs(self.results_dir)
        shutil.copy(srpm, self.results_dir)
        for d in ['BUILD', 'tmp']:
            safe_makedirs(os.path.join(self.results_dir, d))
        cmd = ["rpmbuild"]
        cmd += self.get_rpmbuild_defines(prebuild=False)
        cmd += ["--rebuild", srpm]
        if self.options.has_key('target_arch'):
            cmd += ["--target", self.options['target_arch']]
        err = subprocess.call(cmd)

        # TODO Parse rpmbuild output instead of using glob
        if err:
            raise OSGBuildError('Making RPM failed (command was: '+ " ".join(cmd) +')')
        else:
            rpms = [x for x in glob(os.path.join(self.results_dir, "*.rpm"))
                    if not fnmatch(x, '*.src.rpm')]
            logging.info("The following RPM(s) have been created:\n" +
                         "\n".join(rpms))


    def mock(self):
        """Build the package using mock on the local machine."""
        srpm = self.prebuild()
        safe_makedirs(self.results_dir)

        rpms = self.mock_obj.rebuild(self.results_dir, srpm)
        if self.options['mock_clean']:
            self.mock_obj.clean()
        logging.info("The following RPM(s) have been created:\n" +
                     "\n".join(rpms))


    def koji(self):
        """koji task. Submit a build to koji; add the package first if
        necessary.

        """
        if not self.options['svn'] and not self.koji_obj.can_build_srpm:
            raise OSGBuildError(
"""SRPMs made with rpmbuild 4.8 or newer cannot be submitted to koji.
Use RHEL 5 or a compatible distribution.""")

        koji_target = self.options['koji_target']
        target_build_tag, target_dest_tag = (
            self.koji_obj.get_build_and_dest_tags(koji_target))
        if self.options['koji_tag'] == 'TARGET':
            koji_tag = target_dest_tag
        else:
            koji_tag = self.options['koji_tag']

        self.koji_obj.add_pkg(koji_tag, self.package_name)
        if not self.options['svn']:
            safe_makedirs(self.results_dir)
            srpm = self.prebuild()
            self.koji_obj.build_srpm(koji_target, srpm)
        else:
            self.koji_obj.build_svn(koji_target, *get_package_svn_url_rev(self.package_dir))


    def lint(self):
        if not which("rpmlint"):
            raise ProgramNotFoundError("rpmlint")
        conf_file = find_file("rpmlint.cfg", DATA_FILE_SEARCH_PATH)
        if not conf_file:
            raise FileNotFoundError("rpmlint.cfg", DATA_FILE_SEARCH_PATH)
        srpm = self.prebuild()
        lint_output, lint_returncode = sbacktick(["rpmlint", "-f", conf_file, srpm])

        print lint_output
        if lint_returncode == 0:
            print "rpmlint ok for " + self.package_name
        elif lint_returncode < 64:
            print "Error running rpmlint for " + self.package_name
        elif lint_returncode == 64:
            print "rpmlint found problems with " + self.package_name
        elif lint_returncode == 66:
            print "rpmlint found many problems with " + self.package_name
        else:
            print "unrecognized return code from rpmlint: " + str(lint_returncode)
            




    

def parse_cmdline_args(argv):
    """Parse the arguments given on the command line. Return a tuple containing
    options:    the options object, containing the keyword arguments
    args:       a list containing the positional arguments left over
    optnames:   a list of the option names (valid attributes of 'options')

    """
    parser = OptionParser("""
   %prog TASK PACKAGE1 <PACKAGE2..n> [options]

Valid tasks are:
koji         Build using koji
lint         Discover potential package problems using rpmlint
mock         Build using mock(1) on the local machine
prebuild     Preprocess the package, create SRPM to be submitted, and stop
prepare      Use rpmbuild -bp to unpack and patch the package
quilt        Preprocess the package and run 'quilt setup' on the spec file to unpack the source files and prepare a quilt(1) series file.
rpmbuild     Build using rpmbuild(8) on the local machine
""")
    parser.add_option(
        "-a", "--autoclean", action="store_true",
        help="Clean out the following directories before each build: "
        "'%s', '%s', '%s', '%s'" % (WD_RESULTS, WD_PREBUILD, WD_UNPACKED,
        WD_UNPACKED_TARBALL))
    parser.add_option(
        "--no-autoclean", action="store_false", dest="autoclean",
        help="Disable autoclean")
    parser.add_option(
        "-c", "--cache-prefix",
        help="The prefix for the software cache to take source files from. "
        "The following special caches exist: "
        "AFS (%s), VDT (%s), and AUTO (AFS if avaliable, VDT if not). "
        "The default cache is AUTO." % (AFS_CACHE_PREFIX, WEB_CACHE_PREFIX))
    parser.add_option(
        "-C", "--config-file",
        help="The file to get configuration for this script.")
    parser.add_option(
        "--distro-tag",
        help="The distribution tag to append to the end of the release. "
        "(Default: osg)")
    parser.add_option(
        "--full-extract", action="store_true",
        help="Fully extract all source files.")
    parser.add_option(
        "-k", "--kojilogin", "--koji-login", dest="kojilogin",
        help="The login you use for koji (most likely your CN, e.g."
        "'Matyas Selmeci 564109')")
    parser.add_option(
        "--koji-target",
        help="The koji target to use for building. Default: " +
        DEFAULT_KOJI_TARGET)
    parser.add_option(
        "--koji-tag",
        help="The koji tag to add packages to. The special value TARGET "
        "uses the destination tag defined in the koji target. Default: " +
        DEFAULT_KOJI_TAG)
    parser.add_option(
        "--koji-wrapper", action="store_true", dest="koji_wrapper",
        help="Use the 'osg-koji' koji wrapper. (Default)")
    parser.add_option(
        "--no-koji-wrapper", action="store_false", dest="koji_wrapper",
        help="Do not use the 'osg-koji' koji wrapper, even if found.")
    parser.add_option(
        "--loglevel",
        help="The level of logging the script should do. "
        "Valid values are: DEBUG,INFO,WARNING,ERROR,CRITICAL")
    parser.add_option(
        "--no-mock-clean", action="store_false", dest="mock_clean",
        help="Do not clean the mock buildroot after building (mock task)")
    parser.add_option(
        "-m", "--mock-config",
        help="The location of the mock config file. "
        "defaults to AUTO to use an autogenerated file "
        "recommended for OSG builds")
    parser.add_option(
        "--mock-config-from-koji",
        help="Use a mock config based on a koji buildroot (build tag, "
        "such as el5-osg-build).")
    parser.add_option(
        "--no-wait", "--nowait", action="store_true", dest="no_wait",
        help="Do not wait for the build to finish (koji task)")
    parser.add_option(
        "-q", "--quiet", action="store_const", const="warning", dest="loglevel",
        help="Display less information. Equivalent to --loglevel=warning")
    parser.add_option(
        "--regen-repos", action="store_true",
        help="Perform a regen-repo on the build and destination repos after "
        "each koji build. Allows doing builds that depend on each other. "
        "Use sparingly, as this slows down builds and uses more disk space on "
        "koji-hub.")
    parser.add_option(
        "--scratch", action="store_true",
        help="Perform a scratch build (koji task only)")
    parser.add_option(
        "--svn", action="store_true",
        help="Build package directly from SVN (koji task only, required for RHEL6)")
    parser.add_option(
        "-t", "--target-arch",
        help="The target architecture to build for "
        "(rpmbuild and mock tasks only)")
    parser.add_option(
        "-v", "--verbose", action="store_const", const="debug", dest="loglevel",
        help="Display more information. Equivalent to --loglevel=debug")
    parser.add_option(
        "--version", action="store_true",
        help="Show version and exit.")
    parser.add_option(
        "-w", "--working-directory",
        help="The base directory to use for temporary files made by the "
        "script. If it is 'TEMP', a randomly-named directory under /tmp "
        "is used.")

    optnames = [x.dest for x in parser.option_list if x.dest is not None]

    options, args = parser.parse_args(argv[1:])

    return (options, args, optnames)


def get_task(args):
    """Return the task the user specified in the first positional argument,
    if it is a valid task. Allow the user to enter only the first few
    characters if the task is unambiguous. Raise UsageError if task is
    unspecified, invalid, or ambiguous.

    """
    if len(args) < 1:
        raise UsageError('Need task!')
    task = args[0]

    valid_tasks = ['koji', 'lint', 'mock', 'prebuild', 'prepare', 'quilt', 'rpmbuild']

    matching_tasks = [x for x in valid_tasks if x[0:len(task)] == task]

    if len(matching_tasks) > 1:
        raise UsageError('Ambiguous task. Matching tasks are:' +
                         ", ".join(matching_tasks))
    elif not matching_tasks:
        raise UsageError('No valid task')
    else:
        real_task = matching_tasks[0]

    return real_task


def get_buildopts(options, optnames):
    """Return a dict of the build options to use, based on the config file and
    command-line arguments.

    """
    buildopts = {
        'autoclean': False,
        'cache_prefix': 'AUTO',
        'distro_tag': 'osg',
        'full_extract': False,
        'init_repos': False,
        'kojilogin': None,
        'koji_tag': DEFAULT_KOJI_TAG,
        'koji_target': DEFAULT_KOJI_TARGET,
        'koji_wrapper': True,
        'mock_clean': True,
        'mock_config': 'AUTO',
        'mock_config_from_koji': None,
        'no_wait': False,
        'regen_repos': False,
        'scratch': False,
        'svn': False,
        'target_arch': '',
        'working_directory': '.',
        }

    # Read the config file
    if options.config_file:
        cfg_file = options.config_file
    else:
        if os.path.exists(DEFAULT_CONFIG_FILE):
            cfg_file = DEFAULT_CONFIG_FILE
        else:
            logging.debug("Didn't find default config at %s",
                          DEFAULT_CONFIG_FILE)
            cfg_file = ALT_DEFAULT_CONFIG_FILE

    if os.path.exists(cfg_file):
        cfg = ConfigParser()
        cfg.read(cfg_file)
        buildopts.update(cfg.items('options'))
        logging.debug("Read default config from %s", cfg_file)
    else:
        logging.debug("Config file not found at %s", cfg_file)

    # Overrides from command line
    for optname in optnames:
        optval = getattr(options, optname, None)
        if optval is not None:
            buildopts[optname] = optval

    # Special case for working_directory being TEMP
    if buildopts['working_directory'] == 'TEMP':
        buildopts['working_directory'] = (
            tempfile.mkdtemp(prefix='osg-build-'))
        logging.debug('Working directory is %s',
                        buildopts['working_directory'])

    # Special case for cache_prefix being AFS or VDT
    if buildopts['cache_prefix'] == 'AFS':
        buildopts['cache_prefix'] = AFS_CACHE_PREFIX
    elif buildopts['cache_prefix'] == 'VDT':
        buildopts['cache_prefix'] = WEB_CACHE_PREFIX
    elif buildopts['cache_prefix'] == 'AUTO':
        if os.path.exists(AFS_CACHE_PATH):
            buildopts['cache_prefix'] = AFS_CACHE_PREFIX
        else:
            buildopts['cache_prefix'] = WEB_CACHE_PREFIX

    # --mock-config-from-koji overrides --mock-config
    if buildopts['mock_config_from_koji']:
        buildopts['mock_config'] = None

    return buildopts


def print_version_and_exit():
    if __version__ == '@' + 'VERSION' + '@':
        print "osg-build SVN"
        out, ret = sbacktick("svn info " + sys.argv[0], err2out=True)
        if ret:
            print "no info"
        else:
            print "SVN info:\n" + out
    else:
        print "osg-build " + __version__
    sys.exit(0)


def make_mock_obj(distro_tag, mock_config, mock_config_from_koji, koji_obj, target_arch):
    machine_arch = os.uname()[4]
    if re.search("i[3-6]86", target_arch):
        arch = 'i386'
    elif (re.search("x86_64", target_arch) and not re.search("x86_64", machine_arch)):
        raise OSGBuildError("Can't do 64-bit build on 32-bit machine")
    else:
        arch = machine_arch

    if mock_config:
        if mock_config == "AUTO":
            cfg_dir = tempfile.mkdtemp(prefix="osg-build-mock-")
            atexit.register(shutil.rmtree, cfg_dir)
            cfg_path = make_mock_config(
                arch,
                os.path.join(cfg_dir,"mock-auto-%s.%d.cfg" % (arch, os.getuid())),
                distro_tag)
        else:
            if not mock_config.endswith(".cfg"):
                given_cfg_path = mock_config + ".cfg"
            else:   
                given_cfg_path = mock_config
                
            if given_cfg_path.startswith('/'):
                # Absolute path
                cfg_path = given_cfg_path
            else:
                # Relative path. Can be relative to cwd or /etc/mock. Prefer cwd.
                given_cfg_dir, given_cfg_file = os.path.split(given_cfg_path)
                cfg_dir1 = os.path.abspath(given_cfg_dir)
                cfg_dir2 = os.path.abspath(os.path.join('/etc/mock', given_cfg_dir))
                cfg_path = find_file(given_cfg_file, [cfg_dir1, cfg_dir2])

            #link_mock_extra_config_files(os.path.dirname(cfg_path))

    elif mock_config_from_koji:
        cfg_dir = tempfile.mkdtemp(prefix="osg-build-mock-")
        atexit.register(shutil.rmtree, cfg_dir)
        cfg_path = make_mock_config_from_koji(
            koji_obj,
            arch,
            os.path.join(cfg_dir,"mock-koji-%s-%s.%d.cfg" % (mock_config_from_koji, arch, os.getuid())),
            mock_config_from_koji,
            distro_tag)
    else:
        cfg_path = None

    return Mock(cfg_path, target_arch)


def main(argv=None):
    """Main function."""

    if argv is None: argv=sys.argv

    try:
        options, args, optnames = parse_cmdline_args(argv)

        if options.version:
            print_version_and_exit()
        if options.loglevel:
            try:
                loglevel = int(getattr(logging, options.loglevel.upper()))
            except (TypeError, AttributeError):
                raise UsageError("Invalid log level")
        else:
            loglevel = logging.INFO
        logging.basicConfig(format="%(levelname)s:osg-build:%(message)s",
                            level=loglevel)

        task = get_task(args)
        buildopts = get_buildopts(options, optnames)

        if buildopts['svn'] and task != 'koji':
            raise UsageError("--svn only valid for 'koji' task!")

        if len(args) < 2:
            raise UsageError('Need package directories for this task!')

        mock_obj = None
        koji_obj = None

        if task == 'koji' or (task == 'mock' and buildopts['mock_config_from_koji']):
            koji_obj = Koji(
                koji_wrapper=buildopts['koji_wrapper'],
                kojilogin=buildopts['kojilogin'],
                no_wait=buildopts['no_wait'],
                regen_repos=buildopts['regen_repos'],
                scratch=buildopts['scratch'])
        if task == 'mock':
            mock_obj = make_mock_obj(
                distro_tag=buildopts['distro_tag'],
                mock_config=buildopts['mock_config'],
                mock_config_from_koji=buildopts['mock_config_from_koji'],
                koji_obj=koji_obj,
                target_arch=buildopts['target_arch'])

        package_dirs = args[1:]

        for p in package_dirs:
            if buildopts['svn']:
                if get_package_svn_url_rev(p) is None:
                    raise OSGBuildError("Unable to get SVN info for package dir " + p)
                if check_uncommitted(p):
                    choice = ask("Package directory "+p+" has uncommitted changes"
                                 " that will not be included in the SVN build."
                                 " Continue (yes/no/skip)?", ("y", "n", "s"))
                    if choice[0] == "n":
                        print "Exiting."
                        sys.exit(1)
                    elif choice[0] == "s":
                        print "Skipping."
                        continue
            elif not os.path.isdir(p):
                raise UsageError(p + " isn't a package dir!")

            builder = OSGBuild(p, buildopts, mock_obj=mock_obj, koji_obj=koji_obj)
            getattr(builder, task)()

    except UsageError, e:
        print >>sys.stderr, str(e)
        print >>sys.stderr, "Type '" + sys.argv[0] + " --help' for usage info."
        return 2
    except SystemExit, e:
        return e.code
    except KeyboardInterrupt:
        print >>sys.stderr, ""
        print >>sys.stderr, "-" * 79
        print >>sys.stderr, "Interrupted"
        print >>sys.stderr, "-" * 79
        return 3
    except Error, e:
        print >>sys.stderr, "-" * 79
        print >>sys.stderr, str(e)
        print >>sys.stderr, "-" * 79
        logging.debug("Full traceback follows:")
        logging.debug(e.traceback)
        return 4
    except Exception, e:
        print >>sys.stderr, "-" * 79
        print >>sys.stderr, "An exception occurred:"
        print >>sys.stderr, str(e)
        print >>sys.stderr, "-" * 79
        print >>sys.stderr, "Full traceback follows:"
        traceback.print_exc()
        return 1

    return 0

if __name__ == '__main__':
    sys.exit(main())

